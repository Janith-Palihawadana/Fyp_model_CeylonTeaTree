# -*- coding: utf-8 -*-
"""final_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cey8PpOnJpuP-NXcVc_e-CvCzjA1-fnf
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
print(tf.test.gpu_device_name())

!nvidia-smi

import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

tf.__version__

from tensorflow.keras.layers import Input, Dense, Flatten ,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import ResNet152V2

from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img

import matplotlib.pyplot as plt
import os
import random

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/FYP/Data_set/train

!mkdir train
!mkdir test

train_percent = 0.8
test_percent = 0.1
val_percent = 0.1

import os
import random
from shutil import copyfile

classes = ["algal leaf", "Anthracnose", "bird eye spot", "brown blight", "gray light", "healthy", "red leaf spot", "white spot"]

for c in classes:
    os.makedirs("train/" + c)
    os.makedirs("test/" + c)
    os.makedirs("val/" + c)
    files = os.listdir(c)
    num_train = int(len(files) * train_percent)
    num_test = int(len(files) * test_percent)
    num_val = int(len(files) * val_percent)
    train_files = random.sample(files, num_train)
    test_val_files = list(set(files) - set(train_files))
    test_files = random.sample(test_val_files, num_test)
    val_files = list(set(test_val_files) - set(test_files))
    for f in train_files:
        copyfile(c + "/" + f, "train/" + c + "/" + f)
    for f in test_files:
        copyfile(c + "/" + f, "test/" + c + "/" + f)
    for f in val_files:
        copyfile(c + "/" + f, "val/" + c + "/" + f)

# Resize images
img_height = 224
img_width = 224
image_size = [img_height, img_width, 3] # height, width, depth

# Output classes
predict_class_size = 8

# batch size
bs = 32

# Train/test image path
train_data = '/content/drive/My Drive/FYP/Data_set/train/'
test_data = '/content/drive/My Drive/FYP/Data_set/val/'

model_dict = {ResNet152V2:"resnet152v2"}

def plot_loss_acc(model_history, model_name):
    
    ## Plot loss
    plt.plot(model_history.history['loss'], label='train loss')
    plt.plot(model_history.history['val_loss'], label='test loss')
    plt.legend()
    plt.savefig('/content/drive/My Drive/FYP/Data_set/model8/loss_{}'.format(model_name))
    plt.clf()

    ## Plot Accuracy
    plt.plot(model_history.history['accuracy'], label='train accuracy')
    plt.plot(model_history.history['val_accuracy'], label='test accuracy')
    plt.legend()
    plt.savefig('/content/drive/My Drive/FYP/Data_set/model8/accuracy_{}'.format(model_name))
    plt.clf()

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

def train_model(pre_trained_model):
    
    # Intialize pre trained model (ResNet152V2) with imagenet weights
    pre_trained_net = pre_trained_model(input_shape=image_size, weights='imagenet', include_top=False)

    # Unfreeze some of the layers for fine-tuning
    for layer in pre_trained_net.layers[-15:]:
        layer.trainable = True

    # Add new layers on top of the pre-trained model
    model = tf.keras.models.Sequential()

    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(224,224,3)))
    model.add(MaxPooling2D())
    model.add(tf.keras.layers.Dropout(rate=0.3))

    model.add(Conv2D(32, (3,3), 1, activation='relu'))
    model.add(MaxPooling2D())
    model.add(tf.keras.layers.Dropout(rate=0.3))

    model.add(Conv2D(64, (3,3), 1, activation='relu'))
    model.add(MaxPooling2D())
    model.add(tf.keras.layers.Dropout(rate=0.3))

    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(tf.keras.layers.Dropout(rate=0.3))
    model.add(Dense(8, activation='softmax'))    

    # Set cost and optimization functions for model
    model.compile(loss='categorical_crossentropy', 
                  optimizer='adam', 
                  metrics=['accuracy'])
    
    # Image Data Augmentation using keras ImageDataGenerator
    # train data generator
    train_aug = ImageDataGenerator(rescale=1/255, 
                                   rotation_range=10,                         
                                   zoom_range=0.2, # ~ [1-0.2, 1+0.2]
                                   brightness_range=[0.5,1.5]) # <1 darkens img, >1 brightens img
    # test data generator
    test_aug = ImageDataGenerator(rescale=1/255)

    # Create train/test set
    train_set = train_aug.flow_from_directory(train_data, 
                                              target_size=(img_height,img_width), 
                                              batch_size=bs, 
                                              class_mode='categorical')
    

    test_set = test_aug.flow_from_directory(test_data, 
                                            target_size=(img_height,img_width), 
                                            batch_size=bs, 
                                            class_mode='categorical')   

    # fit the model
    hist = model.fit_generator(train_set, 
                              epochs=50,
                              steps_per_epoch=len(train_set),
                              validation_data=test_set,
                              validation_steps=len(test_set)
                             )
    
    # model name
    model_name = model_dict[pre_trained_model]
    
    # Save model loss/accuracy plots
    plot_loss_acc(hist,model_name)
    
    # Save model
    model.save('/content/drive/My Drive/FYP/Data_set/model8/model_{}.h5'.format(model_name))
    
    print("model {} trained and saved".format(model_name))

for each_model in list(model_dict.keys()):
    train_model(each_model)

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

model = load_model('/content/drive/My Drive/FYP/Data_set/model8/model_resnet152v2.h5')

model.summary()

import numpy as np
import matplotlib.pyplot as plt
import itertools
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img

test_aug = ImageDataGenerator(rescale=1/255)

train_aug = ImageDataGenerator(rescale=1/255, 
                                   rotation_range=10,                         
                                   zoom_range=0.2, # ~ [1-0.2, 1+0.2]
                                   brightness_range=[0.5,1.5]) # <1 darkens img, >1 brightens img

test_data = '/content/drive/My Drive/FYP/Data_set/val/'
train_data = '/content/drive/My Drive/FYP/Data_set/train/'

img_height = 224
img_width = 224
image_size = [img_height, img_width, 3] # height, width, depth
# batch size
bs = 32

test_set = test_aug.flow_from_directory(test_data, 
                                            target_size=(img_height,img_width), 
                                            batch_size=bs, 
                                            class_mode='categorical')   

train_set = train_aug.flow_from_directory(train_data, 
                                              target_size=(img_height,img_width), 
                                              batch_size=bs, 
                                              class_mode='categorical')

# Predict the classes of the test set using the trained model
y_pred = model.predict(test_set)

# Get the class labels of the test set
y_true = test_set.classes

# Get the class names
class_names = list(train_set.class_indices.keys())

# Compute the confusion matrix
cm = confusion_matrix(y_true, np.argmax(y_pred, axis=1))

# Normalize the confusion matrix
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
# Plot the confusion matrix
plt.figure(figsize=(8, 8))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)

fmt = '.2f'
thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, format(cm[i, j], fmt),
             horizontalalignment="center",
             color="white" if cm[i, j] > thresh else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.savefig('/content/drive/My Drive/FYP/Data_set/model8/matrix'.format(confusion_matrix))

from sklearn.metrics import f1_score


# Load the saved model
model = load_model('/content/drive/My Drive/FYP/Data_set/model8/model_resnet152v2.h5')


# Get predictions on test set
y_pred = model.predict(test_set)
y_pred = np.argmax(y_pred, axis=1)

# Calculate F1 score
f1 = f1_score(test_set.classes, y_pred, average='weighted')

print('F1 score:', f1)

model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

from sklearn.metrics import classification_report

# Predict classes for test set
y_pred = model.predict(test_set)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_set.classes

# Generate classification report
report = classification_report(y_true, y_pred_classes, target_names=list(test_set.class_indices.keys()))

print(report)